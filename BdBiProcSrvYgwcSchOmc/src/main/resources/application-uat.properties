#uat环境服务器

#服务端口
server.port=16094
server.tomcat.maxHttpHeaderSize=10240

#MySQL数据库（主数据源）
#spring.datasource.driver-class-name=com.mysql.jdbc.Driver
#spring.datasource.url=jdbc:mysql://172.16.1.126:3306/saas_v1?autoReconnect=true&useSSL=false&useJDBCCompliantTimezoneShift=true&useLegacyDatetimeCode=false&serverTimezone=UTC&useUnicode=true&characterEncoding=UTF-8
#spring.datasource.username=ssic_bi_user
#spring.datasource.password=s3cret
spring.datasource.driver-class-name=com.mysql.jdbc.Driver
spring.datasource.url=jdbc:mysql://172.20.105.58:3306/saas_v1?autoReconnect=true&useSSL=false&useJDBCCompliantTimezoneShift=true&useLegacyDatetimeCode=false&serverTimezone=UTC&useUnicode=true&characterEncoding=UTF-8&rewriteBatchedStatements=true
spring.datasource.username=testappuser
spring.datasource.password=testhdp@ssic.com

#MySQL更多数据库
custom.datasource.names=ds1,ds2,dsHive,dsHive2
#额外数据源1
custom.datasource.ds1.driver-class-name=com.mysql.jdbc.Driver
custom.datasource.ds1.url=jdbc:mysql://172.20.105.58:3306/saas_v1?autoReconnect=true&useSSL=false&useJDBCCompliantTimezoneShift=true&useLegacyDatetimeCode=false&serverTimezone=UTC&useUnicode=true&characterEncoding=UTF-8
custom.datasource.ds1.username=testappuser
custom.datasource.ds1.password=testhdp@ssic.com
#额外数据源2
custom.datasource.ds2.driver-class-name=com.mysql.jdbc.Driver
custom.datasource.ds2.url=jdbc:mysql://172.20.105.58:3306/edu_bd_v1?autoReconnect=true&useSSL=false&useJDBCCompliantTimezoneShift=true&useLegacyDatetimeCode=false&serverTimezone=UTC&useUnicode=true&characterEncoding=UTF-8
custom.datasource.ds2.username=testappuser
custom.datasource.ds2.password=testhdp@ssic.com


#额外数据源3(hive数据库)
custom.datasource.dsHive.driver-class-name=org.apache.hive.jdbc.HiveDriver
custom.datasource.dsHive.url=jdbc:hive2://172.20.105.112:10000/app_saas_v1?autoReconnect=true&useSSL=false&useJDBCCompliantTimezoneShift=true&useLegacyDatetimeCode=false&serverTimezone=UTC&useUnicode=true&characterEncoding=UTF-8
custom.datasource.dsHive.username=
custom.datasource.dsHive.password=
#额外数据源4(hive数据库)
custom.datasource.dsHive2.driver-class-name=org.apache.hive.jdbc.HiveDriver
custom.datasource.dsHive2.url=jdbc:hive2://172.20.105.112:10000/app_saas_v1?autoReconnect=true&useSSL=false&useJDBCCompliantTimezoneShift=true&useLegacyDatetimeCode=false&serverTimezone=UTC&useUnicode=true&characterEncoding=UTF-8
custom.datasource.dsHive2.username=
custom.datasource.dsHive2.password=

#初始化连接
custom.datasource.ds1.initial-size=10
#最大空闲连接
custom.datasource.ds1.max-idle=20
#最小空闲连接
custom.datasource.ds1.min-idle=5
#最大连接数量
custom.datasource.ds1.max-active=50
#是否在自动回收超时连接的时候打印连接的超时错误
custom.datasource.ds1.log-abandoned=true
#是否自动回收超时连接
custom.datasource.ds1.remove-abandoned=true
#超时时间(以秒数为单位)
custom.datasource.ds1.remove-abandoned-timeout=180
##<!-- 超时等待时间以毫秒为单位 6000毫秒/1000等于60秒 -->
custom.datasource.ds1.max-wait=1000
custom.datasource.ds1.test-while-idle=true
#检测数据库的查询语句
custom.datasource.ds1.validation-query=select 1 from dual
custom.datasource.ds1.test-on-borrow=true
#一个连接在池中最小生存的时间(ms)
custom.datasource.ds1.min-evictable-idle-time-millis=600000
#每隔五分钟检测空闲超过10分钟的连接，如600000
custom.datasource.ds1.max-evictable-idle-time-millis=86400000
custom.datasource.ds1.time-between-eviction-runs-millis=300000

#初始化连接
custom.datasource.ds2.initial-size=10
#最大空闲连接
custom.datasource.ds2.max-idle=20
#最小空闲连接
custom.datasource.ds2.min-idle=5
#最大连接数量
custom.datasource.ds2.max-active=50
#是否在自动回收超时连接的时候打印连接的超时错误
custom.datasource.ds2.log-abandoned=true
#是否自动回收超时连接
custom.datasource.ds2.remove-abandoned=true
#超时时间(以秒数为单位)
custom.datasource.ds2.remove-abandoned-timeout=180
##<!-- 超时等待时间以毫秒为单位 6000毫秒/1000等于60秒 -->
custom.datasource.ds2.max-wait=1000
custom.datasource.ds2.test-while-idle=true
#检测数据库的查询语句
custom.datasource.ds2.validation-query=select 1 from dual
custom.datasource.ds2.test-on-borrow=true
#一个连接在池中最小生存的时间(ms)
custom.datasource.ds2.min-evictable-idle-time-millis=600000
#每隔五分钟检测空闲超过10分钟的连接，如600000
custom.datasource.ds2.max-evictable-idle-time-millis=86400000
custom.datasource.ds2.time-between-eviction-runs-millis=300000

#初始化连接
custom.datasource.dsHive.initial-size=10
#最大空闲连接
custom.datasource.dsHive.max-idle=20
#最小空闲连接
custom.datasource.dsHive.min-idle=5
#最大连接数量
custom.datasource.dsHive.max-active=50
#是否在自动回收超时连接的时候打印连接的超时错误
custom.datasource.dsHive.log-abandoned=true
#是否自动回收超时连接
custom.datasource.dsHive.remove-abandoned=true
#超时时间(以秒数为单位)
custom.datasource.dsHive.remove-abandoned-timeout=180
##<!-- 超时等待时间以毫秒为单位 6000毫秒/1000等于60秒 -->
custom.datasource.dsHive.max-wait=1000
custom.datasource.dsHive.test-while-idle=true
#检测数据库的查询语句
custom.datasource.dsHive.validation-query=select 1 from dual
custom.datasource.dsHive.test-on-borrow=true
#一个连接在池中最小生存的时间(ms)
custom.datasource.dsHive.min-evictable-idle-time-millis=600000
#每隔五分钟检测空闲超过10分钟的连接，如600000
custom.datasource.dsHive.max-evictable-idle-time-millis=86400000
custom.datasource.dsHive.time-between-eviction-runs-millis=300000
#custom.datasource.dsHive.testConnectionOnCheckin=300000
#custom.datasource.dsHive.idleConnectionTestPeriod=60

#初始化连接
custom.datasource.dsHive2.initial-size=10
#最大空闲连接
custom.datasource.dsHive2.max-idle=20
#最小空闲连接
custom.datasource.dsHive2.min-idle=5
#最大连接数量
custom.datasource.dsHive2.max-active=50
#是否在自动回收超时连接的时候打印连接的超时错误
custom.datasource.dsHive2.log-abandoned=true
#是否自动回收超时连接
custom.datasource.dsHive2.remove-abandoned=true
#超时时间(以秒数为单位)
custom.datasource.dsHive2.remove-abandoned-timeout=180
##<!-- 超时等待时间以毫秒为单位 6000毫秒/1000等于60秒 -->
custom.datasource.dsHive2.max-wait=1000
custom.datasource.dsHive2.test-while-idle=true
#检测数据库的查询语句
custom.datasource.dsHive2.validation-query=select 1 from dual
custom.datasource.dsHive2.test-on-borrow=true
#一个连接在池中最小生存的时间(ms)
custom.datasource.dsHive2.min-evictable-idle-time-millis=600000
#每隔五分钟检测空闲超过10分钟的连接，如600000
custom.datasource.dsHive2.max-evictable-idle-time-millis=86400000
custom.datasource.dsHive2.time-between-eviction-runs-millis=300000
#custom.datasource.dsHive2.testConnectionOnCheckin=300000
#custom.datasource.dsHive2.idleConnectionTestPeriod=60

#连接池参数配置
spring.datasource.maximum-pool-size=80
spring.datasource.max-idle=10
spring.datasource.max-wait=10000
spring.datasource.min-idle=5
spring.datasource.initial-size=5
spring.datasource.validation-query=SELECT 1
spring.datasource.test-on-borrow=false
spring.datasource.test-while-idle=true
spring.datasource.time-between-eviction-runs-millis=18800

##druid连接池配置(切换为 druid 多数据源时时，使用此配置)
#初始化连接
spring.datasource.druid.initial-size=10
#最大连接数量
spring.datasource.druid.max-active=50
#最小空闲连接
spring.datasource.druid.min-idle=5
#超时等待时间以毫秒为单位
spring.datasource.druid.max-wait=10000
spring.datasource.druid.pool-prepared-statements=true
spring.datasource.druid.max-pool-prepared-statement-per-connection-size=20
#检测数据库的查询语句
spring.datasource.druid.validation-query=select 1
spring.datasource.druid.test-on-borrow=false
spring.datasource.druid.test-on-return=false
spring.datasource.druid.test-while-idle=true
#每隔五分钟检测空闲超过10分钟的连接，如600000
spring.datasource.druid.time-between-eviction-runs-millis=18800
#一个连接在池中最小生存的时间(ms)
spring.datasource.druid.min-evictable-idle-time-millis=300000
#一个连接在池中最大生存的时间(ms)
spring.datasource.druid.max-evictable-idle-time-millis=600000
spring.datasource.druid.filters= stat,wall,log4j

#视频文件服务域名
spring.video.srvdn = http://ygwc-test.tfitsoft.com/video
#报表文件服务域名
spring.repfile.srvdn = http://ygwc-test.tfitsoft.com/repFile
#阳光午餐图片文件服务域名
sunshinelunch.picfile.srvdn = http://uploadpic-cdn.sunshinelunch.com

#Redis运行环境索引，-2表示集群0模式，-1表示集群1模式，否则为单机运行模式（取值范围：0～8）
spring.redis.runenvindex = -1
#Redis运行环境数据库索引
spring.redis.dbindex = 8

#Redis通用配置
redis.maxIdle=300
redis.maxTotal=-1
redis.maxWaitMillis=1000
redis.testOnBorrow=false

#Redis配置0
redis0.host=172.16.1.182
redis0.port=7000
redis0.pass=5O1ecOhLH6bFNlt6
redis0.timeout=10000

#Redis配置1
redis1.host= 172.16.1.182
redis1.port=7001
redis1.pass=5O1ecOhLH6bFNlt6
redis1.timeout=10000

#Redis配置2
redis2.host=172.16.1.183
redis2.port=7002
redis2.pass=5O1ecOhLH6bFNlt6
redis2.timeout=10000

#Redis配置3
redis3.host= 172.16.1.183
redis3.port=7003
redis3.pass=5O1ecOhLH6bFNlt6
redis3.timeout=10000

#Redis配置4
redis4.host=172.16.1.184
redis4.port=7004
redis4.pass=5O1ecOhLH6bFNlt6
redis4.timeout=10000

#Redis配置5
redis5.host= 172.16.1.184
redis5.port=7005
redis5.pass=5O1ecOhLH6bFNlt6
redis5.timeout=10000

#Redis集群配置0
rediscluster0.host=172.16.1.182,172.16.1.182,172.16.1.183,172.16.1.183,172.16.1.184,172.16.1.184
rediscluster0.port=7000,7001,7002,7003,7004,7005
rediscluster0.pass=5O1ecOhLH6bFNlt6,5O1ecOhLH6bFNlt6,5O1ecOhLH6bFNlt6,5O1ecOhLH6bFNlt6,5O1ecOhLH6bFNlt6,5O1ecOhLH6bFNlt6
rediscluster0.timeout=10000,10000,10000,10000,10000,10000

#Redis集群配置1
rediscluster1.host=172.16.10.18,172.16.10.18,172.16.10.37,172.16.10.37,172.16.10.52,172.16.10.52
rediscluster1.port=7000,7001,7002,7003,7004,7005
rediscluster1.pass=5O1ecOhLH6bFNlt6,5O1ecOhLH6bFNlt6,5O1ecOhLH6bFNlt6,5O1ecOhLH6bFNlt6,5O1ecOhLH6bFNlt6,5O1ecOhLH6bFNlt6
rediscluster1.timeout=10000,10000,10000,10000,10000,10000

#Hdfs配置0(默认使用)
hdfscluster0.url=hdfs:// 172.18.14.30:8020
#hdfs0数据文件起始目录
hdfscluster0.dir=

#Hdfs配置1
hdfscluster1.url=hdfs:// 172.18.14.30:8020
#Hdfs配置1目录
hdfscluster1.dir=

#文件服务服务目录
spring.tomcat.filedirs=/opt/data/tomcat/tomcat_video/webapps/ROOT,/opt/data/tomcat/tomcat_repfile/webapps/ROOT

#是否使用测试邮件账号
spring.isUseTestMail = true

#文件服务地址
report.pdf.url = http://ygwc-test.tfitsoft.com/repFile
#模板路径地址
report.pdf.template = http://ygwc-test.tfitsoft.com/repFile/expYgwcOptpdf/report_template.pdf
#新生成文件路径
report.pdf.newfile = /opt/data/expYgwcOptpdf/
#生成到ftp上的路径
report.pdf.ftppath = /expYgwcOptpdf/

#项目域名地址
project.url = http://ygwc-test.tfitsoft.com/

#ftp的ip
ftp.ip = 172.20.105.205
#ftp的端口
ftp.port = 21
#ptp的用户名
ftp.username = ftp-user1
#ftp的密码
ftp.password = 123456
